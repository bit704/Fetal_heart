%matplotlib inline
import os
import numpy as np
import paddle
import paddle.fluid as fluid
from multiprocessing import cpu_count
import matplotlib.pyplot as plt
import random

os.environ['KMP_DUPLICATE_LIB_OK']='True'
os.environ['CUDA_LAUNCH_BLOCKING']='True'

def to_sequence(L):            #将1*2400连续胎心率数据点转化成120*2400胎心率曲线图
    seq=np.array([0 for i in range(2400)],dtype="float32")
    #np.zero(120,2400)好像有点问题
    for i in range(2400):
        if(L[i]<80):
            L[i]=80
        if(L[i]>=200):
            L[i]=200
    seq=np.array(L).astype("float32")
    return seq

def data_reader(data,label,buffered_size=512):
    def reader():
        x=data.shape[0]
        for i in range(0,x):
            seq=to_sequence(data[i])
            yield seq,[label[i]-1]  #算交叉熵label要从0开始
    return reader
def data_reader_drop(data,label,buffered_size=512):
    def reader():
        x=data.shape[0]
        for i in range(0,x):
            if label[i]==1:
                temp=np.random.randint(0,3)
                if temp!=0:
                    continue
            seq=to_sequence(data[i])
            yield seq,[label[i]-1]  #算交叉熵label要从0开始
    return reader
print('begin loading!')  
train_data=np.loadtxt("/home/aistudio/data/data46470/train_data.txt",delimiter=" ",dtype=int)
train_label=np.loadtxt("/home/aistudio/data/data46470/train_label.txt",delimiter=" ",dtype=int)
#train_data=np.loadtxt("external-libraries/try.txt",delimiter=" ",dtype=int)
#train_data_label=np.loadtxt("external-libraries/try_label.txt",delimiter=" ",dtype=int)

test_data=np.loadtxt("/home/aistudio/data/data46470/test_data.txt",delimiter=" ",dtype=int)
test_label=np.loadtxt("/home/aistudio/data/data46470/test_label.txt",delimiter=" ",dtype=int)
#test_data=np.loadtxt("external-libraries/try.txt",delimiter=" ",dtype=int)
#test_data_label=np.loadtxt("external-libraries/try_label.txt",delimiter=" ",dtype=int)
print('successfully loading!')
#构造训练、测试数据提供器
BATCH_SIZE = 32
train_r =data_reader_drop(train_data,train_label)
train_reader =paddle.batch(paddle.reader.shuffle(reader=train_r,buf_size=128),batch_size=BATCH_SIZE)

test_r=data_reader(test_data,test_label)
test_reader = paddle.batch(test_r,batch_size=BATCH_SIZE)

#use_cuda = False
use_cuda = True
place = fluid.CUDAPlace(0) if use_cuda else fluid.CPUPlace()
exe = fluid.Executor(place)

train_program = fluid.default_main_program()
build_program = fluid.default_startup_program()

def net(ipt, typesize):
    HIDDEN_SIZE = 512
    hidden = fluid.layers.fc(input=ipt, size=HIDDEN_SIZE*4,bias_attr=False)

    # 将这个全连接层放入GRU中
    #gru_layer = fluid.layers.dynamic_gru(hidden, size=HIDDEN_SIZE // 3)
    lstm1, cell = fluid.layers.dynamic_lstm(input=hidden, size=HIDDEN_SIZE * 4, use_peepholes=False)
    # 进行池化操作
    pool_layer = fluid.layers.sequence_pool(lstm1, pool_type="")

    # 输出层
    out_layer = fluid.layers.fc(input=pool_layer, size=typesize, act="softmax")
    return out_layer
with fluid.program_guard(train_program, build_program):
    image =fluid.layers.data(name='image', shape=[None, 1], dtype='float32',lod_level=1)
    label =fluid.layers.data(name='label', shape=[None, 1], dtype='int64')
    predict=net(image,3) #分成3类
    cost =fluid.layers.cross_entropy(input=predict, label=label)
    avg_cost =fluid.layers.mean(cost)
    accuracy =fluid.layers.accuracy(input=predict, label=label)

    val_program = train_program.clone(for_test=True)

    opt = fluid.optimizer.Adam(learning_rate=0.0001)
    opt.minimize(avg_cost)

exe.run(build_program)

feeder = fluid.DataFeeder(place=place, feed_list=[image, label])

EPOCH_NUM = 30
#训练过程数据记录
all_train_iters=[]
all_train_costs=[]
all_train_accs=[]


#测试过程数据记录
all_test_iters=[]
all_test_costs=[]
all_test_accs=[]

print('begin training!')
for pass_id in range(EPOCH_NUM):
    
    train_accs = []
    train_costs = []
    zero_cnt=0
    one_cnt=0
    two_cnt=0
    for batch_id, data in enumerate(train_reader()):
        for r in range(len(data)):
            if data[r][1][0]==0:
                zero_cnt+=1
            elif data[r][1][0]==1:
                one_cnt+=1
            else:
                two_cnt+=1
        train_cost,train_acc =exe.run(program=train_program,feed=feeder.feed(data),fetch_list=[avg_cost, accuracy])         #fetch均方误差和准确率        
        train_costs.append(train_cost[0])
        train_accs.append(train_acc[0])
        if batch_id % 200== 0:                                            
            print('Pass:%d, Batch:%d,Cost:%0.5f, Accuracy:%0.5f' %(pass_id, batch_id, train_cost[0],train_acc[0]))
    # 开始测试
    print('zero_cnt:%s'%zero_cnt)
    print('one_cnt:%s'%one_cnt)
    print('two_cnt:%s'%two_cnt)
    test_costs = []                                                        #测试的损失值
    test_accs = []
    print('begin test!')                                                         #测试的准确率
    for batch_id, data in enumerate(test_reader()):
        test_cost, test_acc =exe.run(program=val_program,feed=feeder.feed(data),fetch_list=[avg_cost, accuracy])         #fetch 误差、准确率
        #test_cost, test_acc =exe.run(program=test_program,feed=feeder.feed(data),fetch_list=[avg_cost, accuracy])         #fetch 误差、准确率
        test_costs.append(test_cost[0])                                #记录每个batch的误差
        test_accs.append(test_acc[0])                             #记录每个batch的准确率

    test_cost_average = (sum(test_costs) /len(test_costs))        #计算误差平均值（误差和/误差的个数）
    test_acc_average = (sum(test_accs) /len(test_accs))  #计算准确率平均值（ 准确率的和/准确率的个数）
    train_cost_average = (sum(train_costs) /len(train_costs))
    train_acc_average = (sum(train_accs) /len(train_accs))
    print('Test:%d, Cost:%0.5f, ACC:%0.5f' %(pass_id, test_cost_average, test_acc_average))
    print('Train:%d, Cost:%0.5f, ACC:%0.5f'%(pass_id, train_cost_average, train_acc_average))
	
    all_train_iters.append(pass_id)
    all_train_accs.append(train_acc_average)
    all_train_costs.append(train_cost_average)
    all_test_iters.append(pass_id)
    all_test_accs.append(test_acc_average)
    all_test_costs.append(test_cost_average)

model_save_dir ="/home/aistudio/external-libraries/work"
if not os.path.exists(model_save_dir):
    os.makedirs(model_save_dir)
fluid.io.save_inference_model(model_save_dir,['image'],[predict],exe)
print('savemodels to %s' % (model_save_dir))

def draw_cost_process(title,iters,costs,label_cost):
    plt.title(title, fontsize=24)
    plt.xlabel("epoch", fontsize=20)
    plt.ylabel("cost", fontsize=20)
    plt.plot(iters,costs,color='red',label=label_cost)
    plt.legend()
    plt.grid()
    plt.show()
    
def draw_acc_process(title,iters,acc,label_acc):
    plt.title(title, fontsize=24)
    plt.xlabel("epoch", fontsize=20)
    plt.ylabel("acc", fontsize=20)
    plt.plot(iters,acc,color='green',label=label_acc)
    plt.legend()
    plt.grid()
    plt.show()
    
#调用绘制曲线
draw_acc_process("training",all_train_iters, all_train_accs, "trainning acc")
draw_acc_process("testing",all_test_iters, all_test_accs, "test acc")
draw_cost_process("training",all_train_iters, all_train_costs, "trainning cost")
draw_cost_process("testing",all_test_iters, all_test_costs, "test cost")